{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaos in Several Shapes and Sizes\n",
    "\n",
    "We start our formal discussion of chaos with the definition of sensitive dependence on initial conditions.  \n",
    "\n",
    "> ** Sensitive Dependence on Initial Conditions **: Let $f(x)$ be a map.  We say $x_{0}$ has sensitive dependence on initial conditions if there is a value $d>0$ such that for all $\\epsilon > 0$, there is a point $x\\in I_{\\epsilon}(x_{0})$ such that $\\left|f^{(k)}(x)-f^{(k)}(x_{0})\\right|>d$ for some $k\\in\\mathbb{Z}$.  \n",
    "\n",
    "While not exactly fitting with the definition, we effetively saw this behavior in the shift map $\\sigma$ on the space of two sequences $\\Sigma_{2}$.  If I choose \n",
    "\n",
    "$$\n",
    "{\\bf s} = \\left(s_{0}s_{1}s_{2}\\cdots\\right)\n",
    "$$\n",
    "\n",
    "to be whatever, then I can always choose a sequence ${\\bf s}^{(N)}$ so that \n",
    "\n",
    "$$\n",
    "s^{(N)}_{j} = s_{j}, ~ j\\leq N, ~ s^{(N)}_{N+1}\\neq s_{N+1},\n",
    "$$\n",
    "\n",
    "which then ensures that \n",
    "\n",
    "$$\n",
    "d\\left[\\sigma^{(N+1)}({\\bf s}^{N}),\\sigma^{(N+1)}({\\bf s})\\right] \\geq 1,\n",
    "$$\n",
    "\n",
    "even though\n",
    "\n",
    "$$\n",
    "d\\left[{\\bf s}^{N},{\\bf s}\\right] \\leq \\frac{1}{2^{N}}. \n",
    "$$\n",
    "\n",
    "Now, if we follow the text book, we would make this notion a touch more concrete by looking at the tent map $T_{2}(x)$ where \n",
    "\n",
    "$$\n",
    "T_{2}(x) = \\left\\{ \n",
    "\\begin{array}{rl}\n",
    "2x & 0\\leq x \\leq \\frac{1}{2}\\\\\n",
    "2(1-x) & \\frac{1}{2}< x \\leq 1.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "We see that $T:[0,1]\\rightarrow [0,1]$.  It is also worth pointing out that \n",
    "\n",
    "$$\n",
    "\\left|T'_{2}(x)\\right| = 2>1, ~ x\\neq \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "Now, using the binary representation of numbers, we see there is a natural imbedding, say $\\iota$ of $[0,1]$ into $\\Sigma_{2}$, which comes from using, for $x\\in[0,1]$, \n",
    "\n",
    "$$\n",
    "x = \\frac{1}{2}\\sum_{j=0}^{\\infty}\\frac{b_{j}}{2^{j}}, ~ b_{j}=0,1,\n",
    "$$\n",
    "\n",
    "so that \n",
    "\n",
    "$$\n",
    "\\iota(x) = {\\bf s} = \\left(s_{0}s_{1}s_{2}\\cdots \\right)\n",
    "$$\n",
    "\n",
    "This imbedding does leave us with some awkward decisions as to what to do with $x_{0}=1/2$ since we can just as well say \n",
    "\n",
    "$$\n",
    "\\iota\\left(\\frac{1}{2}\\right) = \\left\\{\\begin{array}{c} (1\\bar{0})\\\\ (0\\bar{1}) \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Likewise, we see any point $x=1/2^{n}$ suffers from the same dilemma of having two equally valid representations.  But setting that issue aside for a moment though, we see that if $x\\in[0,1/2)$, then \n",
    "\n",
    "\\begin{align}\n",
    "T_{2}(x) = & \\sum_{j=0}^{\\infty}\\frac{b_{j}}{2^{j}}, ~ b_{0}=0\\\\\n",
    "= & \\frac{1}{2}\\sum_{j=0}^{\\infty}\\frac{b_{j+1}}{2^{j}}\n",
    "\\end{align}\n",
    "\n",
    "and if $x\\in(1/2,1]$, then \n",
    "\n",
    "\\begin{align}\n",
    "T_{2}(x) = & 2\\left(1-\\sum_{j=0}^{\\infty}\\frac{b_{j}}{2^{j}}\\right), ~ b_{0}=1\\\\\n",
    "= & \\sum_{j=0}^{\\infty}\\frac{1-b_{j}}{2^{j}}, ~ b_{0=1}\\\\\n",
    "= & \\frac{1}{2}\\sum_{j=0}^{\\infty}\\frac{1-b_{j+1}}{2^{j}}\n",
    "\\end{align}\n",
    "\n",
    "So we see that the tent map, viewed with respect to the binary representation of numbers in $[0,1]$, can be represented as a modification of the shift map $\\sigma$ in $\\Sigma_{2}$, i.e. we can write \n",
    "\n",
    "$$\n",
    "T_{2}:\\Sigma_{2}\\rightarrow \\Sigma_{2}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "T_{2}({\\bf s}) = \\left\\{ \n",
    "\\begin{array}{rl}\n",
    "\\sigma({\\bf s}) & s_{0}=0 \\\\\n",
    "\\sigma(\\tau{\\bf s}) & s_{0}=1\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "where $\\tau$ is the parity operator such that \n",
    "\n",
    "$$\n",
    "\\tau({\\bf s})_{j} = 1 - s_{j},\n",
    "$$\n",
    "\n",
    "so that we flip the sign.  \n",
    "\n",
    "_ Problem _: In terms of symbols, what are the 2-cycles of $T_{2}$?  Can you find a 3-cycle?  \n",
    "\n",
    "Thus, it is not too much of a stretch to imagine that we can find cycles of arbitrary period.  \n",
    "\n",
    "Following this line of thought, we can essentially brush past the issues associated with representing points such as $1/2$ since $T_{2}(1/2)=1$, $T_{2}(1)=0$.  This shows that those points which have ambiguous representations have trivial dynamics.  Likewise then, we can show   \n",
    "\n",
    "$$\n",
    "T_{2}\\left(\\frac{1}{4}\\right) = T_{2}\\left(\\frac{3}{4}\\right) = \\frac{1}{2},\n",
    "$$\n",
    "\n",
    "and further \n",
    "\n",
    "_ Problem _: Show that the points \n",
    "\n",
    "$$\n",
    "x_{m,n} = \\frac{m}{2^{n}}, ~ m = 2l+1, ~ l=0,\\cdots,2^{n-1}-1\n",
    "$$\n",
    "\n",
    "satisfy \n",
    "\n",
    "$$\n",
    "T_{2}^{(n-1)}(x_{m,n}) = \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "So, we see that those sequences which end in $\\bar{0}$ or $\\bar{1}$, which as we have shown are essentially the same thing, all eventually end up at the fixed point $0$, i.e. there exists some $n$ such that $T_{2}^{(n)}(x)=0$, which then corresponds to trivial dynamics.\n",
    "\n",
    "Thus, by focusing on those sequences which do not terminate in a repeating sequence of $0$ or $1$, we can not only find cycles of arbitrary period, but we can also establish\n",
    "\n",
    "_ Problem _: Show that we have sensitivity to initial conditions for all points which do not correspond to binary sequences which end in repeating sequences of $0$ and $1$.  \n",
    "\n",
    "## Itineraries in Detail \n",
    "\n",
    "Now, while it is great that we can learn so much about $T_{2}$ in $\\Sigma_{2}$, we should note that our ability to learn so much came down to the relative simplicity of the map itself.  We cannnot always count on this, and so we should develop machinery which allows us to leverage our understanding of the dynamics of sequences for more general maps.  To do so, let us remind ourselves of the definition of a unimodal map\n",
    "\n",
    "> **Unimodal Map**: A function $f$ is said to be unimodal if $f:[0,1]\\rightarrow[0,1]$, $f(0)=f(1)=0$, and there exists a unique point $c\\in(0,1)$ called the _ turning point _ such that $f$ is _ strictly increasing _ on $[0,c)$ and is _ strictly decreasing _ on $(c,1]$. \n",
    "\n",
    "We likewise define an extended symbol space $\\tilde{\\Sigma}_{2}$ where\n",
    "\n",
    "$$\n",
    "\\tilde{\\Sigma}_{2} = \\left\\{{\\bf s} = \\left(s_{0}s_{1}s_{2}\\cdots \\right), ~ s_{j}=0,1,\\tilde{c} \\right\\}\n",
    "$$\n",
    "\n",
    "We now formally define the itinerary of a point $x\\in[0,1]$, say $S(x)\\in\\tilde{\\Sigma}_{2}$, as \n",
    "\n",
    "$$\n",
    "S_{j}(x) = \\left\\{ \\begin{array}{rl} 0, & f^{(j)}(x) \\in [0,c) \\\\ 1, & f^{(j)}(x) \\in (c,1] \\\\ \\tilde{c}, &  f^{(j)}(x)=c \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Thus we use the third symbol to in effect get around the ambiguities that we saw with $x=1/2$ above.  We are going to suppose from here on out that any sequence only has a finite number of occurences of $\\tilde{c}$.  Those points which do not contain $\\tilde{c}$ get singled out so that \n",
    "\n",
    "> **Regular Sequence**: Any sequence not containing the symbol $\\tilde{c}$.  \n",
    "\n",
    "Affiliated with this is what we will call the _ kneading sequence _\n",
    "\n",
    "> **Kneading Sequence**: For a unimodal map, the kneading sequence $K(f)$ is the itinerary of $f(c)$.  \n",
    "\n",
    "Thus for the tent map $T_{2}(x)$, we have $c=1/2$, $T_{2}(1/2)=1$, $T_{2}(1)=0$, $T_{2}(0)=0$. \n",
    "\n",
    "_ Problem _: Show that \n",
    "\n",
    "$$\n",
    "K(T_{2}) = (1\\bar{0}).  \n",
    "$$\n",
    "\n",
    "So looking at itineraries and kneading sequences gives us an idea of the difference between maps which generate simple and complicated dynamics.  For example, if we look at $L_{\\alpha}(x)$ for $1<\\alpha<2$, then we know $x_{\\ast}(\\alpha) = 1-1/\\alpha \\in (0,1/2)$, and that for any point $x\\in(0,1)$, $L_{\\alpha}^{(n)}(x)\\rightarrow x_{\\ast}$.  Lastly, we readily see that \n",
    "\n",
    "$$\n",
    "L_{\\alpha}:[0,1]\\rightarrow [0,\\alpha/4]\\subset [0,1/2), ~ 1<\\alpha<2,\n",
    "$$\n",
    "\n",
    "Thus, the entire space of itineraries for this map is given by \n",
    "\n",
    "$$\n",
    "S(x) = (s_{0}\\bar{0}), ~ s_{0}=0,1,\\tilde{c},\n",
    "$$\n",
    "\n",
    "and we readily see that \n",
    "\n",
    "$$\n",
    "K(L_{\\alpha}) = \\left(\\bar{0}\\right),\n",
    "$$\n",
    "\n",
    "which is about as dull as paint.  \n",
    "\n",
    "We now need a means of keeping track of possible itineraries.  To do this, we come up with a means of comparing them.  Letting $0<\\tilde{c}<1$, we define \n",
    "\n",
    "> **Discrepancy between Sequences**: We say two sequences, say ${\\bf s}$ and ${\\bf t}$ in $\\tilde{\\Sigma}_{2}$ have a discprenancy $n$ if $s_{j}=t_{j}$ for $j=0,\\cdots,n-1$, and $s_{n}\\neq t_{n}$. \n",
    "\n",
    "We then define \n",
    "\n",
    "> ** Counting Operator **: For seqeunce ${\\bf s}$, we define $\\kappa_{n}({\\bf s}) = \\#$ of 1's.  \n",
    "\n",
    "\n",
    "We then define an ordering on sequences via \n",
    "\n",
    "> **Ordering on Sequences**: We say ${\\bf s} < {\\bf t}$ if $\\kappa_{n-1}({\\bf s})$ is even and $s_{n}<t_{n}$ or $\\kappa_{n-1}({\\bf s})$ is odd and $s_{n}>t_{n}$.  \n",
    "\n",
    "This ordering can feel a bit peculiar.  For example \n",
    "\n",
    "$$\n",
    "\\left(0101\\cdots \\right) < \\left(010C\\cdots \\right)  <\\left(0100 \\right).\n",
    "$$\n",
    "\n",
    "But, believe it or not, we get the very beautiful theorem\n",
    "\n",
    "> **Theorem**: For $x,y \\in [0,1]$, if $S(x)<S(y)$, then $x<y$. If $x<y$, then $S(x)\\leq S(y)$.  \n",
    "\n",
    "So that is actually fabulous, especially since for unimodal maps, we have such a clear understanding of when the map $f$ is increasing or decreasing.  To wit, in order to prove this result, we prove the first part via induction.  For sequences with a discrepancy at $0$, since $0<c<1$ and $0<\\tilde{c}<1$, we are done.  Now assume that the result is true for sequences with a discrepancy at $n-1$.  Proceeding to sequences with a discrepancy at $n$, we note that if\n",
    "\n",
    "$$\n",
    "S(x) = \\left(s_{0}s_{1}\\cdots s_{n-1}s_{n}\\cdots\\right), ~ S(y) = \\left(s_{0}s_{1}\\cdots s_{n-1}t_{n}\\cdots\\right)\n",
    "$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "S(f(x)) = \\left(s_{1}\\cdots s_{n-1}s_{n}\\cdots\\right), ~ S(f(y)) = \\left(s_{1}\\cdots s_{n-1}t_{n}\\cdots\\right)\n",
    "$$\n",
    "\n",
    "There are now three cases to work through, $s_{0}=0,\\tilde{c},1$.  Start with $s_{0}=0$.  Now, we assumed $S(x)<S(y)$, so that $S(f(x))<S(f(y))$ which holds since you have not changed the number of $1$'s.  By our inductive hypothesis, we then have that $f(x)<f(y)$, and thus $x<y$ since if $s_{0}=0$, $x,y\\in [0,c)$, on which the map $f$ is strictly increasing.  I leave the rest of the proof to you.  \n",
    "\n",
    "Now the reason for all this formalism comes down to the question of which sequences appear in the itineraries of a map $f$.  To wit, we define\n",
    "\n",
    "> ** Admissable Sequence **: We say a sequence ${\\bf s}\\in\\tilde{\\Sigma}_{2}$ is admissable with respect to a map $f$ if there exists $x$ such that $S(x)={\\bf s}$.  \n",
    "\n",
    "We now see the role of the kneading sequence $K(f)$.  Since $f^{(n)}(x)\\leq f(c)$ for all $n$, if ${\\bf s}$ is admissable, then $\\sigma^{(n)}({\\bf s})\\leq K(f)$ for $n\\geq 1$.  For sufficiency, we have the result\n",
    "\n",
    "> ** Theorem **: If $f$ is unimodal and $c$ is not periodic (thus the finite number of $\\tilde{c}$ requirement), if ${\\bf s}$ is a sequence which satisfies $\\sigma^{(n)}({\\bf s})< K(f)$ for all $n\\geq 1$, then there exists $x\\in [0,1]$ such that $S(x)={\\bf s}$.  \n",
    "\n",
    "\n",
    "Thus we see then that the kneading sequence $K(f)$ determines which sequences are allowed for a given map $f$.  \n",
    "\n",
    "Before we move forward, we need one more technical tool which, frankly, is weird, but as with so many things in mathematics, surprisingly useful.  \n",
    "\n",
    "> ** Schwarzian Derivative **: For a given map $f$, we define its Schwarzian derivative $Sf$ to be \n",
    "$$\n",
    "Sf = \\frac{f'''}{f'} - \\frac{3}{2}\\left(\\frac{f''}{f'}\\right)^{2}\n",
    "$$\n",
    "\n",
    "We have two funny theorems associated with this.  The first is\n",
    "\n",
    "> ** Theorem **: Let $P(x)$ be a polynomial.  If the roots of $P'(x)$ are all real and distinct, then $SP<0$.  \n",
    "\n",
    "> ** Theorem **: Let $Sf<0$ and $Sg<0$.  Then $S(f(g))<0$.    \n",
    "\n",
    "So, we see then that many of our favorite maps have negative Schwarzian derivative, and any iterate has negative Schwarzian as well.  Building off this then, we have \n",
    "\n",
    "> ** Theorem **: If $Sf<0$, and $p$ is either a fixed point or periodic point for $f$, then either a) $p$ has an infinite basin of attraction (i.e. an unbounded interval of points which are attracted to a stable point/cycle $p$), b) there is a critical point (f'(c)=0) of $f$ in the basin of $p$, or c) p is repellant, unstable, or a source (depending on your favorite language). \n",
    "\n",
    "Before we can show this, we need a Lemma\n",
    "\n",
    "> ** Lemma **: If $Sf<0$, then $f'(x)$ cannot have a positive local minimum or a negative local maximum.  \n",
    "\n",
    "Now, suppose that $p$ is a sink fixed point with a finite basin of attraction.  Let $W(p)$ be the biggest open interval, say $(l,r)$, which contains $p$ and is in the basin of $p$.  For the sake of argument, let $0<f'(p)\\leq 1$, since if $f'(p)=0$, we would have a critical point in our basin of attraction.  Now, by assumption $l$ and $r$ are finite, and thus since $f(W(p))\\subset W(p)$, we must have either \n",
    "\\begin{align}\n",
    "f(l) = l, & ~f(r) = r\\\\\n",
    "f(l) = r, & ~f(r) = l\\\\\n",
    "f(l) = f(r)\n",
    "\\end{align}\n",
    "\n",
    "In the first case, by the Mean Value Theorem and the fact that $f(p)=p$, we must have poinst $l<a<p<b<r$ such that $f'(b)=f'(a)=1$.  Since we cannot have a positive local minimum of $f'(x)$ on $[a,b]$, there must be a point $c\\in(a,b)$ at which $f'(c)=0$. I leave the rest of the proof to you.  \n",
    "\n",
    "So we see then that for $L_{\\alpha}(x)$, $0<\\alpha\\leq 4$, we can readily show that there can only ever be at most one attracting fixed point or periodic cycle since no fixed point or cycle can have an infinite basin.  Since there is only one critical point in $[0,1]$, then we can only have one well defined basin for an attractive fixed point or cycle, and thus there can only ever be one at a time.  Otherwise then, every fixed point or cycle must be repellant.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
